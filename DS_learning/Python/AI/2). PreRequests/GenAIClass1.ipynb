{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTeP4rLpItqh",
        "outputId": "ef9772cd-0944-4071-bf83-a31328d853b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.30.3-py3-none-any.whl (320 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.30.3\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount= True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMdLTwCCOh_o",
        "outputId": "b5ff6068-7128-49c7-9a82-51de6edbbc88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = '/content/drive/MyDrive/GenAI/'"
      ],
      "metadata": {
        "id": "spuzjCNoPSWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls '/content/drive/MyDrive/GenAI/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4-o04ROPpXJ",
        "outputId": "74ecbd48-6c53-45c2-c848-eeb36a41cb12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " AI_tutor_system_message_1.txt\t        OpenAI_API_Key.txt\n",
            " AsianPaints.txt\t\t       'Q1FY24 Earnings Call Transcript.pdf'\n",
            " a.txt.gdoc\t\t\t        tata_motors_transcript_sample.txt\n",
            " earnings-call-transcript-q4-fy23.pdf   tata_transcript.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "# openai.api_key = \"dasjdhgashjdg asjkdh aksjhdkashdk\"\n"
      ],
      "metadata": {
        "id": "Syz5glwAPvNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Who won IPL 2023\"}\n",
        "    ]"
      ],
      "metadata": {
        "id": "2_FhQNjAQKna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_response = openai.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo-16k\",\n",
        "  messages=messages\n",
        ")"
      ],
      "metadata": {
        "id": "uV4UmEeTQOeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVaQ648GSGuJ",
        "outputId": "00011e28-6d16-4714-92f7-2c998f0cc942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-9T0MFABodFCRvh1j0eQ5tkhCH0cEJ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"I'm sorry, but I don't have access to real-time information. As of now, IPL 2023 has not happened yet, so I cannot provide you with the winner.\", role='assistant', function_call=None, tool_calls=None))], created=1716699915, model='gpt-3.5-turbo-16k-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=37, prompt_tokens=23, total_tokens=60))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_response.choices[0].message.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "PYEM-BOfSIx7",
        "outputId": "50c1545a-6e98-4ae3-9328-cc407820ddd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I'm sorry, but I don't have access to real-time information. As of now, IPL 2023 has not happened yet, so I cannot provide you with the winner.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''You are a helpful Neural Network teaching assistant.\n",
        "Explain the various optimisation methods in Neural network.\n",
        "Provide an exhaustive summary of the methods describing what they do,\n",
        "sample code for each, and guidelines on when to use which method.\n",
        "'''"
      ],
      "metadata": {
        "id": "E9pPzzdMSXpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message = [{\"role\": \"user\", \"content\": prompt}]\n"
      ],
      "metadata": {
        "id": "bnm-ISyUTj4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_response = openai.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo-16k\",\n",
        "    messages=message,\n",
        "    max_tokens=200,\n",
        "    temperature=0.5,\n",
        "    n=1,\n",
        "    stop=None,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0)\n",
        "\n",
        "chat_response.choices[0].message.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "IrpE9f9uTzO8",
        "outputId": "393f0942-42e9-4bd8-8df1-be81c4751c94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"There are several optimization methods commonly used in neural networks to train models effectively. These methods help in finding the optimal set of weights and biases that minimize the loss function and improve the model's performance. Here is an exhaustive summary of some popular optimization methods, along with sample code and guidelines on when to use each method:\\n\\n1. Gradient Descent (GD):\\n   - GD is the most basic optimization method.\\n   - It updates the weights and biases by taking steps proportional to the negative gradient of the loss function.\\n   - It can be slow for large datasets or complex models.\\n   - Sample code:\\n     ```python\\n     learning_rate = 0.01\\n     for epoch in range(num_epochs):\\n         # Compute gradients\\n         gradients = compute_gradients(loss_function)\\n         # Update weights and biases\\n         weights -= learning_rate * gradients\\n     ```\\n   - Use GD when you have a small dataset or a simple model.\\n\\n2. Stochastic Gradient Descent (SGD):\\n   - SGD\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_response = openai.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo-16k\",\n",
        "    messages = message,\n",
        "    max_tokens=800,\n",
        "    temperature=0.5,\n",
        "    n=1,\n",
        "    stop=None,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0)\n",
        "\n",
        "print(chat_response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHM608qXVcK5",
        "outputId": "aa8049c1-cbf9-4980-ef0d-25960cd03f48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are several optimization methods commonly used in neural networks to train models effectively. These methods help in finding the optimal set of weights and biases that minimize the loss function. Here is an exhaustive summary of some popular optimization methods, along with sample code and guidelines on when to use them:\n",
            "\n",
            "1. Gradient Descent (GD):\n",
            "   - Description: GD is the simplest optimization method where the weights are updated in the opposite direction of the gradient of the loss function.\n",
            "   - Sample Code:\n",
            "     ```python\n",
            "     learning_rate = 0.01\n",
            "     for epoch in range(num_epochs):\n",
            "         # Forward pass\n",
            "         # Calculate loss\n",
            "         \n",
            "         # Backward pass\n",
            "         # Calculate gradients\n",
            "         \n",
            "         # Update weights and biases\n",
            "         weights -= learning_rate * weight_gradients\n",
            "         biases -= learning_rate * bias_gradients\n",
            "     ```\n",
            "   - Guidelines: GD is suitable for small datasets and simple models. It can be slow for large datasets or complex models.\n",
            "\n",
            "2. Stochastic Gradient Descent (SGD):\n",
            "   - Description: SGD is an extension of GD where the weights are updated after each training example instead of the entire dataset.\n",
            "   - Sample Code:\n",
            "     ```python\n",
            "     learning_rate = 0.01\n",
            "     for epoch in range(num_epochs):\n",
            "         for example in training_data:\n",
            "             # Forward pass\n",
            "             # Calculate loss\n",
            "             \n",
            "             # Backward pass\n",
            "             # Calculate gradients\n",
            "             \n",
            "             # Update weights and biases\n",
            "             weights -= learning_rate * weight_gradients\n",
            "             biases -= learning_rate * bias_gradients\n",
            "     ```\n",
            "   - Guidelines: SGD is useful for large datasets as it processes one example at a time, reducing memory requirements. It can be noisy and may require careful tuning of the learning rate.\n",
            "\n",
            "3. Mini-batch Gradient Descent:\n",
            "   - Description: Mini-batch GD is a compromise between GD and SGD, where the weights are updated after processing a small batch of training examples.\n",
            "   - Sample Code:\n",
            "     ```python\n",
            "     batch_size = 32\n",
            "     learning_rate = 0.01\n",
            "     for epoch in range(num_epochs):\n",
            "         for batch in get_batches(training_data, batch_size):\n",
            "             # Forward pass\n",
            "             # Calculate loss\n",
            "             \n",
            "             # Backward pass\n",
            "             # Calculate gradients\n",
            "             \n",
            "             # Update weights and biases\n",
            "             weights -= learning_rate * weight_gradients\n",
            "             biases -= learning_rate * bias_gradients\n",
            "     ```\n",
            "   - Guidelines: Mini-batch GD strikes a balance between the accuracy of GD and the efficiency of SGD. It is the most commonly used optimization method in practice.\n",
            "\n",
            "4. Momentum:\n",
            "   - Description: Momentum helps accelerate GD by adding a fraction of the previous weight update to the current update, allowing the optimization process to overcome small local minima.\n",
            "   - Sample Code:\n",
            "     ```python\n",
            "     learning_rate = 0.01\n",
            "     momentum = 0.9\n",
            "     prev_weight_update = 0\n",
            "     for epoch in range(num_epochs):\n",
            "         # Forward pass\n",
            "         # Calculate loss\n",
            "         \n",
            "         # Backward pass\n",
            "         # Calculate gradients\n",
            "         \n",
            "         # Calculate weight update with momentum\n",
            "         weight_update = learning_rate * weight_gradients + momentum * prev_weight_update\n",
            "         \n",
            "         # Update weights and biases\n",
            "         weights -= weight_update\n",
            "         biases -= learning_rate * bias_gradients\n",
            "         \n",
            "         prev_weight_update = weight_update\n",
            "     ```\n",
            "   - Guidelines: Momentum is useful when dealing with sparse data or noisy gradients. It helps accelerate convergence and overcome small local minima.\n",
            "\n",
            "5. Adam (Adaptive Moment Estimation):\n",
            "   - Description: Adam combines the benefits of momentum and RMSProp by maintaining a running average of both the gradients and their squared values. It adapts the learning rate for each parameter.\n",
            "   - Sample Code:\n",
            "     ```python\n",
            "     learning_rate = 0.001\n",
            "     beta1 = 0.9\n",
            "     beta2 = 0.999\n",
            "     epsilon = 1e-8\n",
            "     m = 0 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_response = openai.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo-16k\",\n",
        "    messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant designed to output JSON to the key 'answer'.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Who won IPL 2020\"}\n",
        "  ]\n",
        ")"
      ],
      "metadata": {
        "id": "26uh03vRVmxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = chat_response.choices[0].message.content\n",
        "\n",
        "# Print the generated output\n",
        "print(output)\n",
        "\n",
        "# Print the type of the output (usually a string)\n",
        "print(\"Output Type:\", type(output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYTHv1-AWfxC",
        "outputId": "1158e02f-c1f7-4e68-aa12-8db36924d243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"answer\": \"Mumbai Indians won IPL 2020\"\n",
            "}\n",
            "Output Type: <class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "json_output = json.loads(output)\n",
        "\n",
        "result = json_output.get('answer', \"None\")\n",
        "\n",
        "# The 'result' variable now contains the value associated with the 'answer' key or \"None\" if the key is not present.\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPv5ERr9WkMs",
        "outputId": "8a2d32ee-8184-4901-b211-40043dd66af6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mumbai Indians won IPL 2020\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QM4A19BmWqRl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}